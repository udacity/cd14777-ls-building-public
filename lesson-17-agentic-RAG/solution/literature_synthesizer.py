# main.py

import os
import json
import re
from typing import List, TypedDict, Dict, Any

import chromadb
from openai import OpenAI
from langgraph.graph import StateGraph, END

from dotenv import load_dotenv
# Load environment variables from a .env file (for OPENAI_API_KEY)
load_dotenv("../../../.env")

# Import the pre-defined functions for querying biomedical APIs
from ls_action_space.action_space import (
    query_pubmed,
    query_clinvar
)

# --- Configuration ---
# It's best practice to use environment variables for API keys.
# Set OPENAI_API_KEY in your environment.
if "OPENAI_API_KEY" not in os.environ:
    raise ValueError("OPENAI_API_KEY environment variable not set.")

# Initialize clients
client = OpenAI(base_url="https://openai.vocareum.com/v1")
db_client = chromadb.PersistentClient(path="./gene_disease_db")
collection = db_client.get_or_create_collection(name="gene_disease_literature")
MAX_ITERATIONS = 3


# --- LangGraph State Definition ---

class GraphState(TypedDict):
    """
    Represents the state of our agent's thought process.

    Attributes:
        question: The initial user query.
        key_terms: Essential terms (gene, disease, mechanisms) extracted from the question.
        documents: A list of retrieved documents used as context.
        answer: The synthesized answer generated by the LLM.
        missing_terms: A list of key terms not found in the generated answer.
        iterations: The number of refinement cycles completed.
    """
    question: str
    key_terms: List[str]
    documents: List[str]
    answer: str
    missing_terms: List[str]
    iterations: int


# --- Agent Nodes ---

def extract_key_terms(state: GraphState) -> Dict[str, Any]:
    """
    Identifies the core gene, disease, and mechanism keywords from the user's question.
    This step sets the requirements for the final answer.
    """
    print("--- üî¨ EXTRACTING KEY TERMS ---")
    question = state['question']

    prompt = f"""
    From the following question, identify the primary gene, disease, and up to 2
    critical biological keywords (e.g., mechanisms, pathways).
    Return a JSON object with keys: "gene", "disease", "keywords" (a list of strings).

    Question: "{question}"
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": "You are a biomedical expert."},
                  {"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    data = json.loads(response.choices[0].message.content)
    key_terms = [data['gene'], data['disease']] + data.get('keywords', [])
    print(f"üîë Key Terms Identified: {key_terms}")

    return {"key_terms": key_terms, "iterations": 0}


def retrieve_and_embed(state: GraphState) -> Dict[str, Any]:
    """
    Fetches data from PubMed and ClinVar, embeds it, stores it in ChromaDB,
    and retrieves the most relevant documents for the current question.
    """
    print("\n--- üìö RETRIEVING & EMBEDDING DOCUMENTS ---")
    question = state['question']
    key_terms = state['key_terms']

    # Formulate a search query. On refinement loops, focus on missing terms.
    if state.get('missing_terms'):
        search_query = f"{key_terms[0]} {key_terms[1]} {' '.join(state['missing_terms'])}"
        print(f"Refining search for missing terms: {search_query}")
    else:
        search_query = ' AND '.join(key_terms)
        print(f"Initial search query: {search_query}")

    # 1. Fetch data from live APIs
    pubmed_docs = query_pubmed(search_query, max_results=5)
    clinvar_doc = query_clinvar(key_terms[0])

    # 2. Process and prepare documents for embedding
    processed_docs = []
    doc_ids = []

    for doc in pubmed_docs:
        content = f"Title: {doc['title']}\nAbstract: {doc['abstract']}"
        pmid = f"pmid_{doc['pmid']}"
        if pmid not in doc_ids:
            processed_docs.append(content)
            doc_ids.append(pmid)

    if clinvar_doc and 'error' not in clinvar_doc:
        content = f"ClinVar: {clinvar_doc['title']}. Significance: {clinvar_doc['clinical_significance']}. Conditions: {', '.join(clinvar_doc['conditions'])}"
        vcv_id = f"vcv_{clinvar_doc['accessions']['VCV'][0]}" if clinvar_doc['accessions'].get(
            'VCV') else f"gene_{key_terms[0]}"
        if vcv_id not in doc_ids:
            processed_docs.append(content)
            doc_ids.append(vcv_id)

    print(f"Found {len(processed_docs)} new documents to potentially add to DB.")

    # 3. Embed and store in ChromaDB if they don't already exist
    existing_docs = collection.get(ids=doc_ids)
    new_doc_indices = [i for i, doc_id in enumerate(doc_ids) if doc_id not in existing_docs['ids']]

    if new_doc_indices:
        new_docs_to_embed = [processed_docs[i] for i in new_doc_indices]
        new_ids = [doc_ids[i] for i in new_doc_indices]

        embeddings = client.embeddings.create(
            input=new_docs_to_embed, model="text-embedding-3-small"
        ).data

        collection.add(
            embeddings=[e.embedding for e in embeddings],
            documents=new_docs_to_embed,
            ids=new_ids
        )
        print(f"Added {len(new_ids)} new documents to ChromaDB.")

    # 4. Query ChromaDB using a manually embedded query to ensure model consistency
    print("Embedding user question with OpenAI for ChromaDB query...")
    query_embedding = client.embeddings.create(
        input=[question],
        model="text-embedding-3-small"
    ).data[0].embedding

    results = collection.query(
        query_embeddings=[query_embedding],  # Use the pre-computed vector
        n_results=5
    )

    retrieved_documents = results['documents'][0]

    print(f"Retrieved {len(retrieved_documents)} documents from DB for synthesis.")
    return {"documents": retrieved_documents}


def generate_answer(state: GraphState) -> Dict[str, str]:
    """Synthesizes a final answer using the retrieved context."""
    print("\n--- ‚úçÔ∏è GENERATING ANSWER ---")
    question = state['question']
    documents = state['documents']

    context = "\n\n---\n\n".join(documents)
    prompt = f"""
    Based *only* on the following context, provide a clear and concise answer to the user's question.
    If the context is insufficient, state that.

    CONTEXT:
    {context}

    QUESTION:
    {question}

    ANSWER:
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": "You are a scientific writer."},
                  {"role": "user", "content": prompt}]
    )
    answer = response.choices[0].message.content
    print("Generated Answer Snippet:", answer[:200] + "...")
    return {"answer": answer}


def critique_answer(state: GraphState) -> Dict[str, Any]:
    """Checks if the generated answer contains all required key terms."""
    print("\n--- ü§î CRITIQUING ANSWER ---")
    answer = state['answer']
    key_terms = state['key_terms']

    # Use regex for case-insensitive word boundary matching
    missing_terms = [
        term for term in key_terms
        if not re.search(r'\b' + re.escape(term) + r'\b', answer, re.IGNORECASE)
    ]

    if not missing_terms:
        print("‚úÖ All key terms are covered. Finalizing.")
    else:
        print(f"‚ùå Missing key terms: {missing_terms}. Will attempt refinement.")

    return {
        "missing_terms": missing_terms,
        "iterations": state['iterations'] + 1
    }


def decide_to_finish(state: GraphState) -> str:
    """Determines whether to end the process or loop for refinement."""
    if not state['missing_terms'] or state['iterations'] >= MAX_ITERATIONS:
        return "finish"
    else:
        return "refine"


# --- Build and Compile the Graph ---

workflow = StateGraph(GraphState)

# Add nodes to the graph
workflow.add_node("extract_key_terms", extract_key_terms)
workflow.add_node("retrieve_and_embed", retrieve_and_embed)
workflow.add_node("generate_answer", generate_answer)
workflow.add_node("critique_answer", critique_answer)

# Define the workflow edges
workflow.set_entry_point("extract_key_terms")
workflow.add_edge("extract_key_terms", "retrieve_and_embed")
workflow.add_edge("retrieve_and_embed", "generate_answer")
workflow.add_edge("generate_answer", "critique_answer")

# Add the conditional edge for the self-correction loop
workflow.add_conditional_edges(
    "critique_answer",
    decide_to_finish,
    {
        "refine": "retrieve_and_embed",  # Loop back to retrieve more specific info
        "finish": END
    }
)

# Compile the graph into a runnable application
app = workflow.compile()

# --- Main Execution ---

if __name__ == "__main__":
    # Example question that requires specific mechanistic terms
    question = "What is the mechanism linking the BRCA1 gene to ovarian cancer, specifically mentioning homologous recombination?"

    print(f"üöÄ Starting Agent for Question: \"{question}\"\n")

    # Define the initial state
    initial_state = {"question": question}

    # Run the agent
    final_state = app.invoke(initial_state)

    # --- Display Final Results ---
    print("\n" + "=" * 50)
    print("‚ú® AGENT RUN COMPLETE ‚ú®")
    print("=" * 50)
    print(f"\n‚ùì Original Question:\n   {final_state['question']}")
    print(f"\nüîë Key Terms Required:\n   {final_state['key_terms']}")
    print(f"\nüìù Final Answer:\n   {final_state['answer']}")
    print("-" * 50)

    if final_state.get('missing_terms'):
        print(
            f"‚ö†Ô∏è Warning: Could not include the following terms after {final_state['iterations']} attempts: {final_state['missing_terms']}")
    else:
        print(
            f"‚úÖ Success: All key terms were successfully included in the answer within {final_state['iterations']} iteration(s).")
    print("=" * 50)